#!/usr/bin/env python3
"""
SaNaé¡¹ç›®ä¸»å…¥å£è„šæœ¬
"""

import argparse
import logging
import sys
from pathlib import Path
import yaml

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from etl.extract import ExcelExtractor
from etl.transform import DataTransformer
from etl.load import DataLoader
from features.build_t0 import T0FeatureBuilder
from features.build_img_embed import ImageEmbeddingBuilder
from models.train import ModelTrainer
from eval.cv_loco import CVLOCOEvaluator
from eval.reporting import ResultReporter

def setup_logging(log_level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('sana.log')
        ]
    )

def run_etl(config_path: str):
    """è¿è¡ŒETLæµç¨‹"""
    print("ğŸ”„ å¼€å§‹ETLæµç¨‹...")

    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # 1. æ•°æ®æå–
    extractor = ExcelExtractor(config)
    all_data = extractor.extract_all_sheets()

    # 2. æ•°æ®è½¬æ¢
    transformer = DataTransformer(config)
    df_transformed = transformer.transform_all_centers(all_data)

    # 3. æ•°æ®åŠ è½½
    load_config = config.copy()
    load_config['output_dir'] = 'data/artifacts'
    loader = DataLoader(load_config)
    tables = loader.load_data_contracts(df_transformed)

    # 4. ä¿å­˜ç»“æœ
    saved_paths = loader.save_tables(tables)

    print("âœ… ETLæµç¨‹å®Œæˆ!")
    return tables

def run_features(config_path: str):
    """è¿è¡Œç‰¹å¾å·¥ç¨‹"""
    print("ğŸ”§ å¼€å§‹ç‰¹å¾å·¥ç¨‹...")

    # åŠ è½½ETLç»“æœ
    artifacts_dir = Path('data/artifacts')
    latest_artifact = max(artifacts_dir.iterdir()) if artifacts_dir.exists() else None

    if not latest_artifact:
        print("âŒ æœªæ‰¾åˆ°ETLç»“æœï¼Œè¯·å…ˆè¿è¡ŒETLæµç¨‹")
        return None

    # åŠ è½½æ•°æ®è¡¨
    patients_df = pd.read_parquet(latest_artifact / 'patients.parquet')
    surgery_cpb_df = pd.read_parquet(latest_artifact / 'surgery_cpb.parquet')
    labs_long_df = pd.read_parquet(latest_artifact / 'labs_long.parquet')
    imaging_meta_df = pd.read_parquet(latest_artifact / 'imaging_meta.parquet')
    outcomes_df = pd.read_parquet(latest_artifact / 'outcomes.parquet')

    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # æ„å»ºT0ç‰¹å¾
    t0_builder = T0FeatureBuilder(config.get('features', {}))
    t0_features = t0_builder.build_t0_features(
        patients_df, surgery_cpb_df, labs_long_df, imaging_meta_df
    )

    # æ„å»ºå½±åƒåµŒå…¥ï¼ˆå¦‚æœæœ‰å½±åƒæ•°æ®ï¼‰
    image_features = None
    img_config = config.get('image_features', {})
    if img_config:
        img_builder = ImageEmbeddingBuilder(img_config)
        image_features = img_builder.build_embeddings(imaging_meta_df)

    print("âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ!")
    return t0_features, image_features, outcomes_df

def run_training(config_path: str, view: str = "Primary_set_img"):
    """è¿è¡Œæ¨¡å‹è®­ç»ƒ"""
    print("ğŸ¤– å¼€å§‹æ¨¡å‹è®­ç»ƒ...")

    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # å‡†å¤‡æ•°æ®
    feature_data = run_features(config_path)
    if not feature_data:
        print("âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
        return

    t0_features, image_features, outcomes_df = feature_data

    # åˆå¹¶æ•°æ®
    surgery_cpb_df = pd.read_parquet(Path('data/artifacts') / max(Path('data/artifacts').iterdir()) / 'surgery_cpb.parquet')
    patients_df = pd.read_parquet(Path('data/artifacts') / max(Path('data/artifacts').iterdir()) / 'patients.parquet')

    # è®­ç»ƒæ¨¡å‹
    trainer = ModelTrainer(config)
    trainer.setup_models()

    # å‡†å¤‡è®­ç»ƒæ•°æ®
    prepared_data = trainer.prepare_data(
        patients_df, surgery_cpb_df,
        pd.read_parquet(Path('data/artifacts') / max(Path('data/artifacts').iterdir()) / 'labs_long.parquet'),
        pd.read_parquet(Path('data/artifacts') / max(Path('data/artifacts').iterdir()) / 'imaging_meta.parquet'),
        outcomes_df
    )

    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    training_results = trainer.train_all_models(prepared_data)

    # ä¿å­˜ç»“æœ
    results_dir = trainer.save_results()
    model_cards = trainer.generate_model_cards()

    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    return training_results, results_dir

def run_evaluation(config_path: str, results_dir: str):
    """è¿è¡Œæ¨¡å‹è¯„ä¼°"""
    print("ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...")

    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = CVLOCOEvaluator(config.get('evaluation', {}))

    # ç”ŸæˆæŠ¥å‘Š
    reporter = ResultReporter()

    print("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ!")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="SaNa - Aå‹ä¸»åŠ¨è„‰å¤¹å±‚å¤šä¸­å¿ƒAIé¢„æµ‹ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python main.py etl --config configs/etl.yml
  python main.py train --config configs/train_primary.yml
  python main.py evaluate --config configs/train_primary.yml --results results/
        """
    )

    parser.add_argument(
        'command',
        choices=['etl', 'features', 'train', 'evaluate', 'all'],
        help='è¦æ‰§è¡Œçš„å‘½ä»¤'
    )

    parser.add_argument(
        '--config',
        type=str,
        default='configs/train_primary.yml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '--view',
        type=str,
        default='Primary_set_img',
        help='æ•°æ®è§†å›¾åç§°'
    )

    parser.add_argument(
        '--results',
        type=str,
        default='results/',
        help='ç»“æœç›®å½•'
    )

    parser.add_argument(
        '--log-level',
        type=str,
        default='INFO',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        help='æ—¥å¿—çº§åˆ«'
    )

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—
    setup_logging(args.log_level)

    print("ğŸš€ SaNa - Aå‹ä¸»åŠ¨è„‰å¤¹å±‚å¤šä¸­å¿ƒAIé¢„æµ‹ç³»ç»Ÿ")
    print("=" * 50)

    try:
        if args.command == 'etl':
            run_etl('configs/etl.yml')

        elif args.command == 'features':
            run_features(args.config)

        elif args.command == 'train':
            run_training(args.config, args.view)

        elif args.command == 'evaluate':
            run_evaluation(args.config, args.results)

        elif args.command == 'all':
            # å®Œæ•´æµç¨‹
            print("è¿è¡Œå®Œæ•´æµç¨‹: ETL -> ç‰¹å¾å·¥ç¨‹ -> æ¨¡å‹è®­ç»ƒ")

            # 1. ETL
            tables = run_etl('configs/etl.yml')

            # 2. ç‰¹å¾å·¥ç¨‹
            feature_data = run_features(args.config)

            # 3. æ¨¡å‹è®­ç»ƒ
            if feature_data:
                training_results, results_dir = run_training(args.config, args.view)

                # 4. æ¨¡å‹è¯„ä¼°
                if results_dir:
                    run_evaluation(args.config, results_dir)

        print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")

    except Exception as e:
        logging.error(f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()